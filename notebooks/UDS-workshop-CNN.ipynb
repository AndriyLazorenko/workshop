{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--<h1 style=\"font-size:40px; font-family:Verdana\" align=\"center\"> UDS-Club Workshop </h1> -->\n",
    "<h2 style=\"font-size:34px; font-family:Verdana\" align=\"center\"> Convolutional Neural Networks </h2>\n",
    "<img src='http://i.piccy.info/i9/666d78be04fbcf04fdb321d5953d1fa5/1492256847/123248/1137898/ua_parrots.jpg'/>\n",
    "<h4 style=\"font-size:18px; font-family:Verdana\" align=\"right\"> by Iryna Melnyk <br> <pre>    2017-04-23</pre> </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "[Requirements](##Requirements)  \n",
    "[Classification for Sentiment Analysis](#Classification-for-Sentiment-Analysis)  \n",
    "[CNN](#CNN)  \n",
    "[History](#History)  \n",
    "[Model overview](#CNN-Model-overview)  \n",
    "[Proc and Cons](#CNN-Proc-and-Cons)  \n",
    "[Main params](#CNN-Main-params)  \n",
    "[Practice](#CNN-Practice)   \n",
    "[Conclusions](#Conclusions)   \n",
    "[Useful links](#CNN-Useful-links)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "1. Python 3.x (or Anaconda3 for Python 3.5, https://www.continuum.io/downloads)\n",
    "2. Scikit-learn 0.18.x (pip install scikit-learn==0.18.1, http://scikit-learn.org/)\n",
    "3. Keras latest (https://keras.io/#installation)\n",
    "4. Pandas latest (http://pandas.pydata.org/)\n",
    "5. For datasets more than 1M reviews min Hardware Requirements (SDRAM >= 8 GB)\n",
    "\n",
    "[To the table of contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification for Sentiment Analysis\n",
    "\n",
    "\n",
    "Main tasks:\n",
    "- supervised learning\n",
    "- focus on the binary classification problem in which you can take on only two values, 0 and 1.\n",
    "- predict sentiment of users review text\n",
    "\n",
    "We are trying to build a sentiment classifier for users reviews about movies (consumers goods, books, etc.),  \n",
    "then x(i) may be some features of user review, and y may be 1 if it is a piece of spam mail, and 0 otherwise.  \n",
    "0 is also called the negative class, and 1 is the positive class,  \n",
    "and they are sometimes also denoted by the symbols “-” and “+.” Given x (i) ,  \n",
    "the corresponding y (i) is also called the label for the training example.\n",
    "\n",
    "\n",
    "[To the table of contents](#Table-of-Contents)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History\n",
    "\n",
    "1957, Frank Rosenblatt - perceptron, Cornell Aeronautical Laboratory\n",
    "\n",
    "1959, Hubel & Wiesel found that cells in animal visual cortex are responsible for detecting light in receptive fields\n",
    "\n",
    "1975, Kunihiko Fukushima - cognitron as an extension of original perceptron\n",
    "\n",
    "1980, Kunihiko Fukushima - neocognitron - predecessor of CNN\n",
    "\n",
    "1990, LeCun et all showed that back-propagation and several of its generalizations could be derived rigorously using Lagrange functions [LeCun, 1988]\n",
    "\n",
    "1990s to 2012: In the years from late 1990s to early 2010s convolutional neural network were in incubation. As more and more data and computing power became available, tasks that convolutional neural networks could tackle became more and more interesting\n",
    "\n",
    "2012, Alex Krizhevsky (and others) released AlexNet which was a deeper and much wider version of the LeNet and won by a large margin the difficult ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012. It was a significant breakthrough with respect to the previous approaches and the current widespread application of CNNs can be attributed to this work\n",
    "\n",
    "2013, Matthew Zeiler and Rob Fergus developed the ZFNet (short for Zeiler & Fergus Net). It was an improvement on AlexNet by tweaking the architecture hyperparameters\n",
    "\n",
    "2014, Szegedy (and others). GoogLeNet - the main contribution was the development of an Inception Module that dramatically reduced the number of parameters in the network (4M, compared to AlexNet with 60M)\n",
    "\n",
    "2014, Karen Simonyan and Andrew Zisserman of the University of Oxford, VGGNet - its main contribution was in showing that the depth of the network (number of layers) is a critical component for good performance. It scored first place on the image localization task and second place on the image classification task. Localization is finding where in the image a certain object is, described by a bounding box. Classification is describing what the object in the image is. This predicts a category label\n",
    "\n",
    "2015, Kaiming He (and others), Residual Network. ResNets are currently by far state of the art Convolutional Neural Network models and are the default choice for using ConvNets in practice (as of May 2016)\n",
    "\n",
    "2016, Xingyu Zeng (and others), Gated Bi-directional CNN for Object Detection\n",
    "\n",
    "[To the table of contents](#Table-of-Contents)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model overview  \n",
    "\n",
    "A basic CNN consists of several types of layers: convolutional, pooling and fully connected layer and we will try to get an intuition about how it works under the hood.\n",
    "\n",
    "** The theory of convolution **\n",
    "\n",
    "Convolution is a technique widely used in the image processing. It is the process of adding each element of the image to its local neighbors, weighted by the kernel. \n",
    "<img src=\"http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif\" style=\"width: 60%;\"/>\n",
    "It results in a wide range of effects such as blurring, sharpening, embossing, edge detection and more depending on a filter.\n",
    "<img src=\"http://cs231n.github.io/assets/cnn/convnet.jpeg\" alt=\"hidden layers visualisation\" style=\"width: 100%;\"/>\n",
    "\n",
    "** Filters **\n",
    "\n",
    "In the regular sense a filter (aka kernel) is a matrix of predefined parameters (or weights). But in CNN we use a self adjusted filters. This is achieved through the usage of backpropagation algorithm. \n",
    "At first step the filter weights are initialized with relatively small random values which leads to asymmetrical diversity among \"neurons\" and better classification capability (zero initialisation is not recommended because every \"neuron\" in the network will compute the same output)\n",
    "\n",
    "** Pooling **\n",
    " \n",
    "To reduce the dimensionality of obtained intermediate data and to condense the sparsity the pooling layer is used. We simply chose a region size and pick the maximum value (MaxPooling) or average among the region (AveragePooling).\n",
    "<img src=\"https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-10-at-3-38-39-am.png?w=494\" style=\"width: 80%;\"/>\n",
    "\n",
    "** Fully connected layer **\n",
    "\n",
    "The final layer which takes as an input the data from convolutional or pooling layer and outputs an N dimensional vector where N is the number of classes that the program has to choose from.\n",
    "\n",
    "** CNN for sentiment analysis **\n",
    "\n",
    "Instead of image pixels, the input to most NLP tasks are sentences or documents represented as a matrix. Each row of the matrix corresponds to one token, typically a word, but it could be a character. That is, each row is vector that represents a word. Typically, these vectors are word embeddings (low-dimensional representations) like word2vec or GloVe, but they could also be one-hot vectors that index the word into a vocabulary. For a 10 word sentence using a 100-dimensional embedding we would have a 10×100 matrix as our input. That’s our “image”.\n",
    "<img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-12.05.40-PM-1024x937.png\" style=\"width: 100%;\"/>\n",
    "\n",
    "[To the table of contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### CNN Proc and Cons\n",
    "\n",
    "** Pros **\n",
    "\n",
    "    + Accuracy is high when we have enough data to train\n",
    "    + The best choice for Computer Vision tasks and position-dependent data\n",
    "\n",
    "** Cons **\n",
    "    - Shows better results on large datasets\n",
    "    - Train could be time-consuming\n",
    "    - High computational cost\n",
    "\n",
    "\n",
    "\n",
    "[To the table of contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Main params\n",
    "\n",
    "** keras.layers.Conv1D **\n",
    "\n",
    "** filters **: Integer, the dimensionality of the output space (i.e. the number output of filters in the convolution).\n",
    "\n",
    "** kernel_size **: An integer or tuple/list of a single integer, specifying the length of the 1D convolution window.\n",
    "\n",
    "** activation **: Activation function to use (see activations). If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "\n",
    "\n",
    "[To the table of contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, GlobalAveragePooling1D\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_EPOCH = 2\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "METRICS = ['accuracy', 'fmeasure']\n",
    "labels_index = {'negative': 0, 'positive': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"../data/movie_reviews.csv\", sep=',')\n",
    "data_test = pd.read_csv(\"../data/test.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152610, 2)\n",
      "(10660, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 152610 entries, 0 to 152609\n",
      "Data columns (total 2 columns):\n",
      "label    152610 non-null int64\n",
      "text     152610 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.587498\n",
       "0    0.412502\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = ['href','quot','amp','br',\n",
    "                    'an','by','did','does','was',\n",
    "                    'were','the','to','at','on',\n",
    "                    'in','with','it','he','she',\n",
    "                    'this','that','is']\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    string = re.sub(r\"can\\'t\", \"can not\", str(string))\n",
    "    string = re.sub(r\"\\'s\", \" is\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" have\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" not\", string)\n",
    "    string = re.sub(r\"\\'re\", \" are\", string)\n",
    "    string = re.sub(r\"\\'d\", \" would\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" will\", string)\n",
    "    string = re.sub(r\"\\b[A-Za-z]{1}\\b\", ' ', string)\n",
    "    string = re.sub(r\"[^A-Za-z-_]\", \" \", string)\n",
    "    string = re.sub(r'\\.{1,10}', ' ', string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "def preprocessing(dataframe):\n",
    "#     dataframe = dataframe[:500]\n",
    "    dataframe['text'] = dataframe.loc[:,'text'].apply(clean_str)\n",
    "    dataframe['text'] = dataframe.loc[:,'text'].apply(remove_stopwords)\n",
    "    dataframe = dataframe[dataframe['text'].notnull()]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_seq_model(layer):\n",
    "    model = Sequential()\n",
    "    model.add(layer)\n",
    "    model.add(Conv1D(64, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(256, 3, activation='relu'))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(labels_index), activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Lets try to make our own layered pie! Implement the model with the following parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click to see more</summary>\n",
    "  <img src=\"https://raw.githubusercontent.com/udsclub/workshop/master/pictures/model.png\" style=\"width: 100%;\"/>\n",
    "  Don't forget to uncomment the model creation and recompile it\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_another_model(layer):\n",
    "    model = Sequential()\n",
    "    model.add(layer)\n",
    "    # place your code here\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = preprocessing(data_train)\n",
    "data_test = preprocessing(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text\n",
      "0      1  entire generation of filmgoers just might repr...\n",
      "1      1  pixar classic one of best kids movies of all time\n",
      "2      1  apesar de representar um imenso avan o tecnol ...\n",
      "3      1  when woody perks up opening scene not only toy...\n",
      "4      1  introduced not one but two indelible character...\n"
     ]
    }
   ],
   "source": [
    "print (data_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(data_train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(data_train.text)\n",
    "word_index = tokenizer.word_index\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = to_categorical(np.asarray(data_train.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "                                                    data, \n",
    "                                                    labels,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(tokenizer.word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            input_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework challenge\n",
    "\n",
    "We can replace our embedding_layer using GloVe and retrain our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click to see more</summary>\n",
    "  <p align='left'>You can use this code snippet to solve the challenge. For this task we need to download glove.6B.zip from https://nlp.stanford.edu/projects/glove/</p>\n",
    "      <pre>\n",
    "          <code>\n",
    "GLOVE_DIR = \"path/to/glove\"\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# At this point we can leverage our embedding_index dictionary and our word_index to compute our embedding matrix:\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "# We load this embedding matrix into an Embedding layer. Note that we set trainable=False to prevent the weights from being updated during training.\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "          </code>\n",
    "      </pre>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 50, 50)        5811950     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 48, 64)        9664        embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 24, 64)        0           convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 22, 128)       24704       maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 11, 128)       0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 9, 256)        98560       maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "globalaveragepooling1d_1 (Global (None, 256)           0           convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 256)           0           globalaveragepooling1d_1[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2)             514         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 5,945,392\n",
      "Trainable params: 5,945,392\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_seq_model(embedding_layer)\n",
    "# model = create_another_model(embedding_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS) # SGD(lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 122088 samples, validate on 30522 samples\n",
      "Epoch 1/2\n",
      "122088/122088 [==============================] - 181s - loss: 0.4894 - acc: 0.7590 - fmeasure: 0.7590 - val_loss: 0.4295 - val_acc: 0.8015 - val_fmeasure: 0.8015\n",
      "Epoch 2/2\n",
      "122088/122088 [==============================] - 257s - loss: 0.3805 - acc: 0.8295 - fmeasure: 0.8295 - val_loss: 0.4266 - val_acc: 0.8039 - val_fmeasure: 0.8039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6f11c56d8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "          nb_epoch=NB_EPOCH, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(data_test['text'])\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = to_categorical(np.asarray(data_test['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.67      0.75      5330\n",
      "          1       0.73      0.89      0.80      5330\n",
      "\n",
      "avg / total       0.79      0.78      0.78     10660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return 1 if x > 0.5 else 0\n",
    "f = np.vectorize(f, otypes=[np.int])\n",
    "b_scores = f(scores)\n",
    "print(classification_report(labels, b_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10656/10660 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 45.73%\n",
      "acc: 78.00%\n",
      "fmeasure: 78.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"%s: %.2f%%\" % (model.metrics_names[0], score[0]*100))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[2], score[2]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "ConvNets are based on the ability to generalize the position-dependent data and they are useful not only in image classification and NLP. The most recent win of Google’s AlphaGo Project over Lee Sedol in the Go game series relied on a CNN at its core. The self-driving cars which, in the coming years, will arguably become a regular sight on our streets, rely on CNNs for steering. \n",
    "\n",
    "[To the table of contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Useful links\n",
    "\n",
    "http://ufldl.stanford.edu/tutorial/supervised/ConvolutionalNeuralNetwork/\n",
    "\n",
    "http://cs231n.github.io/neural-networks-1/ \n",
    "\n",
    "https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "https://keras.io/models/sequential/\n",
    "\n",
    "https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html \n",
    "\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "\n",
    "http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/\n",
    "\n",
    "[To the table of contents](#Table-of-Contents)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
